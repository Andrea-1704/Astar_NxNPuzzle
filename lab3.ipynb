{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deadline: 24 novembre ore 23:59.\n",
    "Solve efficiently a generic n^2-1 puzzle using path search algorithm.\n",
    "\n",
    "Cost=  total number of actions you need to __evaluate__. An action is something that bring me to a new state. For example the number of swaps to do.\n",
    "\n",
    "The result is the sequence of action that took you at the end. The goal is not to find a state but a sequence of actions from srtarting point to end point: we do not look for a soluzion but for a sequence of actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Inizialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from heapq import heappop, heappush\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 7\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the quality of a solution (list of actions) as the total number of actions needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualily(actions):\n",
    "    return len(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state is a numpy array.\n",
    "\n",
    "We created a function that returns the number of actions from a state pos1 to a state pos2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute 100_000 random actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100000/100000 [00:01<00:00, 56277.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27, 30, 41, 12, 13, 26, 17],\n",
       "       [40,  0, 36, 43, 47, 48, 42],\n",
       "       [ 3, 31, 37, 10,  2, 18,  6],\n",
       "       [16, 35,  4, 11, 23,  8, 21],\n",
       "       [ 5, 24, 14, 20, 15, 45, 25],\n",
       "       [ 7, 39, 34,  9, 33, 46, 44],\n",
       "       [32, 29, 22, 19, 38, 28,  1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that indicates if we end the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_goal(solution):\n",
    "    arr_solution = np.reshape(solution, PUZZLE_DIM*PUZZLE_DIM)\n",
    "    arr_solution_no_zero = arr_solution[0: len(arr_solution)-1]\n",
    "    if np.all(arr_solution_no_zero[:-1] <= arr_solution_no_zero[1:]) and arr_solution[len(arr_solution)-1]==0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to try to convert the numpy ndarray into a bytes object directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_bytes(state: np.ndarray) -> bytes:\n",
    "    return state.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As heuristic functions we can now try to use 3 different heuristics: \n",
    "1. manhattan distance\n",
    "2. linear conflict\n",
    "3. walking distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleHeuristicService:\n",
    "    def __init__(self, goal_state: np.ndarray):\n",
    "        self.goal_state = goal_state\n",
    "\n",
    "    def heuristic_manhattan_distance(self, position):\n",
    "        distance = 0\n",
    "        size = len(position)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                tile = position[i][j]\n",
    "                if tile != 0:\n",
    "                    target_row = (tile - 1) // size\n",
    "                    target_col = (tile - 1) % size\n",
    "                    distance += abs(i - target_row) + abs(j - target_col)\n",
    "        return distance\n",
    "    \n",
    "\n",
    "    def heuristic_linear_conflict(self, position):\n",
    "        conflict = 0\n",
    "        size = len(position)\n",
    "\n",
    "        # Row conflicts\n",
    "        for row in range(size):\n",
    "            max_val = -1\n",
    "            for col in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0 and (value - 1) // size == row:\n",
    "                    if value > max_val:\n",
    "                        max_val = value\n",
    "                    else:\n",
    "                        conflict += 2\n",
    "\n",
    "        # Column conflicts\n",
    "        for col in range(size):\n",
    "            max_val = -1\n",
    "            for row in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0 and (value - 1) % size == col:\n",
    "                    if value > max_val:\n",
    "                        max_val = value\n",
    "                    else:\n",
    "                        conflict += 2\n",
    "\n",
    "        return conflict\n",
    "\n",
    "    def heuristic_walking_distance(self, position):\n",
    "        # Create a grid to store the walking distances\n",
    "        size = len(position)\n",
    "        distance_grid = [[0] * size for _ in range(size)]\n",
    "\n",
    "        for row in range(size):\n",
    "            for col in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0:\n",
    "                    target_row = (value - 1) // size\n",
    "                    target_col = (value - 1) % size\n",
    "                    distance_grid[row][col] = abs(row - target_row) + abs(col - target_col)\n",
    "\n",
    "        # Calculate the walking distance\n",
    "        walking_distance = 0\n",
    "        for row in range(size):\n",
    "            for col in range(size):\n",
    "                walking_distance += distance_grid[row][col]\n",
    "\n",
    "        return walking_distance\n",
    "\n",
    "    def combined_heuristic(self, state: np.ndarray) -> int:\n",
    "        if PUZZLE_DIM<=3:\n",
    "            return self.heuristic_manhattan_distance(state)\n",
    "        if PUZZLE_DIM<=5:\n",
    "            return 1*(self.heuristic_manhattan_distance(state) + self.heuristic_linear_conflict(state) + self.heuristic_walking_distance(state))\n",
    "        return 5*(self.heuristic_manhattan_distance(state) + self.heuristic_linear_conflict(state) + self.heuristic_walking_distance(state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_a_star(initial_state: np.ndarray, final_state: np.ndarray) -> Tuple[Union[list, None], float]:\n",
    "    \"\"\"\n",
    "    Enhanced A* algorithm for the n-puzzle problem using modular heuristics.\n",
    "    \"\"\"\n",
    "    heuristic_service = PuzzleHeuristicService(final_state)\n",
    "\n",
    "    def calculate_heuristic(state: np.ndarray) -> int:\n",
    "        return heuristic_service.combined_heuristic(state)\n",
    "\n",
    "    # Priority queue: (f_score, g_score, current_state, path)\n",
    "    open_set = []\n",
    "    heappush(open_set, (calculate_heuristic(initial_state), 0, initial_state.tobytes(), []))\n",
    "    visited = set()\n",
    "    optimum = state_to_bytes(final_state)\n",
    "\n",
    "    cost = 0\n",
    "\n",
    "    while open_set:\n",
    "        # Extract node with the lowest f score (f score= cost)\n",
    "        f_score, g_score, current_bytes, path = heappop(open_set)\n",
    "        current_state = np.frombuffer(current_bytes, dtype=initial_state.dtype).reshape(initial_state.shape)\n",
    "        current_score = state_to_bytes(current_state)\n",
    "\n",
    "        # Check if we finished already:\n",
    "        if current_score == optimum:\n",
    "            return path, float(cost) \n",
    "\n",
    "        # Add current node to visited\n",
    "        visited.add(current_score)\n",
    "\n",
    "        # Generate possible moves:\n",
    "        for act in available_actions(current_state):\n",
    "            next_state = do_action(current_state, act)\n",
    "            next_score = state_to_bytes(next_state)\n",
    "            if next_score in visited:\n",
    "                continue\n",
    "\n",
    "            cost += 1\n",
    "\n",
    "            # update scores:\n",
    "            new_g_score = g_score + 1\n",
    "            new_f_score = new_g_score + calculate_heuristic(next_state)\n",
    "\n",
    "            # Add new state to openset\n",
    "            heappush(open_set, (new_f_score, new_g_score, next_state.tobytes(), path + [act]))\n",
    "\n",
    "    return None, float('inf')  # No solution found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_goal = np.arange(1, PUZZLE_DIM*PUZZLE_DIM, 1)\n",
    "test_goal = np.append(test_goal, 0)\n",
    "test_goal = test_goal.reshape((PUZZLE_DIM, PUZZLE_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m actions, costValue \u001b[38;5;241m=\u001b[39m \u001b[43menhanced_a_star\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_goal\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[105], line 42\u001b[0m, in \u001b[0;36menhanced_a_star\u001b[1;34m(initial_state, final_state)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# update scores:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m new_g_score \u001b[38;5;241m=\u001b[39m g_score \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 42\u001b[0m new_f_score \u001b[38;5;241m=\u001b[39m new_g_score \u001b[38;5;241m+\u001b[39m \u001b[43mcalculate_heuristic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Add new state to openset\u001b[39;00m\n\u001b[0;32m     45\u001b[0m heappush(open_set, (new_f_score, new_g_score, next_state\u001b[38;5;241m.\u001b[39mtobytes(), path \u001b[38;5;241m+\u001b[39m [act]))\n",
      "Cell \u001b[1;32mIn[105], line 8\u001b[0m, in \u001b[0;36menhanced_a_star.<locals>.calculate_heuristic\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_heuristic\u001b[39m(state: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mheuristic_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombined_heuristic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 72\u001b[0m, in \u001b[0;36mPuzzleHeuristicService.combined_heuristic\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PUZZLE_DIM\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheuristic_manhattan_distance(state) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheuristic_linear_conflict(state) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheuristic_walking_distance(state))\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1_000_000\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheuristic_manhattan_distance(state) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheuristic_linear_conflict(state) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheuristic_walking_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[104], line 57\u001b[0m, in \u001b[0;36mPuzzleHeuristicService.heuristic_walking_distance\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m     55\u001b[0m             target_row \u001b[38;5;241m=\u001b[39m (value \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m size\n\u001b[0;32m     56\u001b[0m             target_col \u001b[38;5;241m=\u001b[39m (value \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m size\n\u001b[1;32m---> 57\u001b[0m             distance_grid[row][col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(row \u001b[38;5;241m-\u001b[39m target_row) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate the walking distance\u001b[39;00m\n\u001b[0;32m     60\u001b[0m walking_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actions, costValue = enhanced_a_star(state, test_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualily(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43585.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 27, 12, 29, 10, 25],\n",
       "       [20,  9, 28, 34, 21, 11],\n",
       "       [18, 30,  4, 32,  0,  1],\n",
       "       [26, 24,  6, 31, 13, 17],\n",
       "       [ 7, 35, 22, 16,  8,  2],\n",
       "       [23,  3, 15,  5, 33, 14]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12],\n",
       "       [13, 14, 15, 16, 17, 18],\n",
       "       [19, 20, 21, 22, 23, 24],\n",
       "       [25, 26, 27, 28, 29, 30],\n",
       "       [31, 32, 33, 34, 35,  0]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_goal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
