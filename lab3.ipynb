{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deadline: 24 novembre ore 23:59.\n",
    "Solve efficiently a generic n^2-1 puzzle using path search algorithm.\n",
    "\n",
    "Cost=  total number of actions you need to __evaluate__. An action is something that bring me to a new state. For example the number of swaps to do.\n",
    "\n",
    "The result is the sequence of action that took you at the end. The goal is not to find a state but a sequence of actions from srtarting point to end point: we do not look for a soluzion but for a sequence of actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Inizialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from heapq import heappop, heappush\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 5\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the quality of a solution (list of actions) as the total number of actions needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualily(actions):\n",
    "    return len(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state is a numpy array.\n",
    "\n",
    "We created a function that returns the number of actions from a state pos1 to a state pos2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute 100_000 random actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100000/100000 [00:00<00:00, 116211.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14,  8,  9,  1, 18],\n",
       "       [22,  0, 15,  5, 17],\n",
       "       [ 2, 11, 21, 16,  4],\n",
       "       [19, 12, 13,  6, 24],\n",
       "       [20,  3,  7, 23, 10]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that indicates if we end the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_goal(solution):\n",
    "    arr_solution = np.reshape(solution, PUZZLE_DIM*PUZZLE_DIM)\n",
    "    arr_solution_no_zero = arr_solution[0: len(arr_solution)-1]\n",
    "    if np.all(arr_solution_no_zero[:-1] <= arr_solution_no_zero[1:]) and arr_solution[len(arr_solution)-1]==0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a function that computes a value for each matrix so that it will be easy to store matrices.\n",
    "\n",
    "This function shouuld be bi-directional: a number is associated to only one matrix and viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_score(matrix):\n",
    "    \"\"\"\n",
    "    Performs the product for each element with the position in the matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - state (np.ndarray): A state of the puzzle.\n",
    "    \n",
    "    Returns:\n",
    "    - Score of the matrix\n",
    "    \"\"\"\n",
    "    #flatter the matrix:\n",
    "    matrice = matrix.flatten()\n",
    "    score = 0\n",
    "    for i in range(len(matrice)):\n",
    "        score += (10**i)*matrice[i]\n",
    "    return int(score)\n",
    "\n",
    "\n",
    "def simplified_matrix_score(matrix):\n",
    "    \"\"\"\n",
    "    Performs the product for each element with the position in the matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - state (np.ndarray): A state of the puzzle.\n",
    "    \n",
    "    Returns:\n",
    "    - Score of the matrix\n",
    "    \"\"\"\n",
    "    #flatter the matrix:\n",
    "    matrice = matrix.flatten()\n",
    "    score = 0\n",
    "    for i in range(len(matrice)):\n",
    "        score += i*matrice[i]\n",
    "    return int(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "import numpy as np\n",
    "\n",
    "# Define action as a named tuple\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])\n",
    "\n",
    "def depth_limited_search(initial_state: np.ndarray, final_state: np.ndarray, max_depth: int) -> list[action] or None:\n",
    "    \"\"\"\n",
    "    Performs a depth-limited search to solve the n-puzzle.\n",
    "    \n",
    "    Parameters:\n",
    "    - initial_state (np.ndarray): The starting state of the puzzle.\n",
    "    - final_state (np.ndarray): The desired goal state of the puzzle.\n",
    "    - max_depth (int): The maximum depth limit for the search.\n",
    "    \n",
    "    Returns:\n",
    "    - list[action] or None: A sequence of actions leading to the solution, or None if no solution is found.\n",
    "    \"\"\"\n",
    "    stack = deque([(initial_state, [], 0)])  # Stack of (current state, path to reach it, current depth)\n",
    "    visited = set()  # Set of visited states for current path only\n",
    "    optimum = matrix_score(final_state)\n",
    "\n",
    "    while stack:\n",
    "        current_state, path, depth = stack.pop()\n",
    "        current_score = matrix_score(current_state)\n",
    "\n",
    "        # Check if we reached the goal\n",
    "        if current_score == optimum:\n",
    "            return path\n",
    "        \n",
    "        # # Backtrack if depth limit reached\n",
    "        # if depth >= max_depth:\n",
    "        #     continue\n",
    "        \n",
    "        # Add current state to visited set (track only in current path)\n",
    "        visited.add(current_score)\n",
    "        \n",
    "        # Generate and iterate over all possible moves\n",
    "        for act in available_actions(current_state):\n",
    "            next_state = do_action(current_state, act)\n",
    "            \n",
    "            # Check if the next state has already been visited in the current path\n",
    "            if matrix_score(next_state) not in visited:\n",
    "                # Add the new state and path to stack, increase depth\n",
    "                stack.append((next_state, path + [act], depth + 1))\n",
    "        \n",
    "        # Remove the current state from visited set after backtracking\n",
    "        #visited.remove(matrix_score(current_state))\n",
    "    \n",
    "    return None  # Return None if no solution is found within depth limit\n",
    "\n",
    "# Iterative Deepening Depth-First Search (IDDFS) wrapper function\n",
    "def iterative_deepening_dfs(initial_state: np.ndarray, final_state: np.ndarray, max_depth: int = 50) -> list[action] or None:\n",
    "    \"\"\"\n",
    "    Performs an iterative deepening DFS to solve the n-puzzle.\n",
    "    \n",
    "    Parameters:\n",
    "    - initial_state (np.ndarray): The starting state of the puzzle.\n",
    "    - final_state (np.ndarray): The desired goal state of the puzzle.\n",
    "    - max_depth (int): The maximum depth to limit the search for IDDFS.\n",
    "    \n",
    "    Returns:\n",
    "    - list[action] or None: A sequence of actions leading to the solution, or None if no solution is found.\n",
    "    \"\"\"\n",
    "    for depth in range(1, max_depth + 1):\n",
    "        result = depth_limited_search(initial_state, final_state, depth)\n",
    "        if result is not None:\n",
    "            return result\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to try to convert the numpy ndarray into a bytes object directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_bytes(state: np.ndarray) -> bytes:\n",
    "    return state.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As heuristic functions we can now try to use 3 different heuristics: \n",
    "1. manhattan distance\n",
    "2. linear conflict\n",
    "3. walking distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleHeuristicService:\n",
    "    def __init__(self, goal_state: np.ndarray):\n",
    "        self.goal_state = goal_state\n",
    "\n",
    "    def heuristic_manhattan_distance(self, position):\n",
    "        distance = 0\n",
    "        size = len(position)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                tile = position[i][j]\n",
    "                if tile != 0:\n",
    "                    target_row = (tile - 1) // size\n",
    "                    target_col = (tile - 1) % size\n",
    "                    distance += abs(i - target_row) + abs(j - target_col)\n",
    "        return distance\n",
    "\n",
    "    def linear_conflict(self, state: np.ndarray) -> int:\n",
    "        conflict = 0\n",
    "        size = state.shape[0]\n",
    "        for row in range(size):\n",
    "            row_goal = self.goal_state[row]\n",
    "            row_state = state[row]\n",
    "            for i in range(size):\n",
    "                for j in range(i + 1, size):\n",
    "                    if (\n",
    "                        row_state[i] in row_goal\n",
    "                        and row_state[j] in row_goal\n",
    "                        and row_state[i] > row_state[j]\n",
    "                    ):\n",
    "                        conflict += 2\n",
    "        return conflict\n",
    "    \n",
    "\n",
    "    def heuristic_linear_conflict(self, position):\n",
    "        conflict = 0\n",
    "        size = len(position)\n",
    "\n",
    "        # Row conflicts\n",
    "        for row in range(size):\n",
    "            max_val = -1\n",
    "            for col in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0 and (value - 1) // size == row:\n",
    "                    if value > max_val:\n",
    "                        max_val = value\n",
    "                    else:\n",
    "                        conflict += 2\n",
    "\n",
    "        # Column conflicts\n",
    "        for col in range(size):\n",
    "            max_val = -1\n",
    "            for row in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0 and (value - 1) % size == col:\n",
    "                    if value > max_val:\n",
    "                        max_val = value\n",
    "                    else:\n",
    "                        conflict += 2\n",
    "\n",
    "        return conflict\n",
    "\n",
    "    def heuristic_walking_distance(self, position):\n",
    "        # Create a grid to store the walking distances\n",
    "        size = len(position)\n",
    "        distance_grid = [[0] * size for _ in range(size)]\n",
    "\n",
    "        for row in range(size):\n",
    "            for col in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0:\n",
    "                    target_row = (value - 1) // size\n",
    "                    target_col = (value - 1) % size\n",
    "                    distance_grid[row][col] = abs(row - target_row) + abs(col - target_col)\n",
    "\n",
    "        # Calculate the walking distance\n",
    "        walking_distance = 0\n",
    "        for row in range(size):\n",
    "            for col in range(size):\n",
    "                walking_distance += distance_grid[row][col]\n",
    "\n",
    "        return walking_distance\n",
    "\n",
    "    def combined_heuristic(self, state: np.ndarray) -> int:\n",
    "        #return self.manhattan_distance(state) + self.linear_conflict(state)\n",
    "        return self.heuristic_manhattan_distance(state) + self.heuristic_linear_conflict(state) + self.heuristic_walking_distance(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_a_star(initial_state: np.ndarray, final_state: np.ndarray) -> Tuple[Union[list, None], float]:\n",
    "    \"\"\"\n",
    "    Enhanced A* algorithm for the n-puzzle problem using modular heuristics.\n",
    "    \"\"\"\n",
    "    heuristic_service = PuzzleHeuristicService(final_state)\n",
    "\n",
    "    def calculate_heuristic(state: np.ndarray) -> int:\n",
    "        return heuristic_service.combined_heuristic(state)\n",
    "\n",
    "    # Priority queue: (f_score, g_score, current_state, path)\n",
    "    open_set = []\n",
    "    heappush(open_set, (calculate_heuristic(initial_state), 0, initial_state.tobytes(), []))\n",
    "    visited = set()\n",
    "    optimum = state_to_bytes(final_state)\n",
    "\n",
    "    cost = 0\n",
    "\n",
    "    while open_set:\n",
    "        # Extract node with the lowest f score (f score= cost)\n",
    "        f_score, g_score, current_bytes, path = heappop(open_set)\n",
    "        current_state = np.frombuffer(current_bytes, dtype=initial_state.dtype).reshape(initial_state.shape)\n",
    "        current_score = state_to_bytes(current_state)\n",
    "\n",
    "        # Check if we finished already:\n",
    "        if current_score == optimum:\n",
    "            return path, float(cost) \n",
    "\n",
    "        # Add current node to visited\n",
    "        visited.add(current_score)\n",
    "\n",
    "        # Generate possible moves:\n",
    "        for act in available_actions(current_state):\n",
    "            next_state = do_action(current_state, act)\n",
    "            next_score = state_to_bytes(next_state)\n",
    "            if next_score in visited:\n",
    "                continue\n",
    "\n",
    "            cost += 1\n",
    "\n",
    "            # update scores:\n",
    "            new_g_score = g_score + 1\n",
    "            new_f_score = new_g_score + calculate_heuristic(next_state)\n",
    "\n",
    "            # Add new state to openset\n",
    "            heappush(open_set, (new_f_score, new_g_score, next_state.tobytes(), path + [act]))\n",
    "\n",
    "    return None, float('inf')  # No solution found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_goal = np.arange(1, PUZZLE_DIM*PUZZLE_DIM, 1)\n",
    "test_goal = np.append(test_goal, 0)\n",
    "test_goal = test_goal.reshape((PUZZLE_DIM, PUZZLE_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the upgrade depth search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth_limited_search(state, test_goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the A* algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, costValue = enhanced_a_star(state, test_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualily(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Action(pos1=(1, 1), pos2=(1, 0)),\n",
       " Action(pos1=(1, 0), pos2=(2, 0)),\n",
       " Action(pos1=(2, 0), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(0, 2)),\n",
       " Action(pos1=(0, 2), pos2=(0, 3)),\n",
       " Action(pos1=(0, 3), pos2=(1, 3)),\n",
       " Action(pos1=(1, 3), pos2=(1, 4)),\n",
       " Action(pos1=(1, 4), pos2=(2, 4)),\n",
       " Action(pos1=(2, 4), pos2=(2, 3)),\n",
       " Action(pos1=(2, 3), pos2=(1, 3)),\n",
       " Action(pos1=(1, 3), pos2=(1, 4)),\n",
       " Action(pos1=(1, 4), pos2=(0, 4)),\n",
       " Action(pos1=(0, 4), pos2=(0, 3)),\n",
       " Action(pos1=(0, 3), pos2=(1, 3)),\n",
       " Action(pos1=(1, 3), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(0, 1)),\n",
       " Action(pos1=(0, 1), pos2=(0, 2)),\n",
       " Action(pos1=(0, 2), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(1, 0)),\n",
       " Action(pos1=(1, 0), pos2=(0, 0)),\n",
       " Action(pos1=(0, 0), pos2=(0, 1)),\n",
       " Action(pos1=(0, 1), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(1, 0)),\n",
       " Action(pos1=(1, 0), pos2=(2, 0)),\n",
       " Action(pos1=(2, 0), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(2, 3)),\n",
       " Action(pos1=(2, 3), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(4, 1)),\n",
       " Action(pos1=(4, 1), pos2=(4, 0)),\n",
       " Action(pos1=(4, 0), pos2=(3, 0)),\n",
       " Action(pos1=(3, 0), pos2=(2, 0)),\n",
       " Action(pos1=(2, 0), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(4, 2)),\n",
       " Action(pos1=(4, 2), pos2=(4, 1)),\n",
       " Action(pos1=(4, 1), pos2=(4, 0)),\n",
       " Action(pos1=(4, 0), pos2=(3, 0)),\n",
       " Action(pos1=(3, 0), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(3, 4)),\n",
       " Action(pos1=(3, 4), pos2=(2, 4)),\n",
       " Action(pos1=(2, 4), pos2=(1, 4)),\n",
       " Action(pos1=(1, 4), pos2=(1, 3)),\n",
       " Action(pos1=(1, 3), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 0)),\n",
       " Action(pos1=(3, 0), pos2=(2, 0)),\n",
       " Action(pos1=(2, 0), pos2=(1, 0)),\n",
       " Action(pos1=(1, 0), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(4, 3)),\n",
       " Action(pos1=(4, 3), pos2=(4, 2)),\n",
       " Action(pos1=(4, 2), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(3, 4)),\n",
       " Action(pos1=(3, 4), pos2=(4, 4)),\n",
       " Action(pos1=(4, 4), pos2=(4, 3)),\n",
       " Action(pos1=(4, 3), pos2=(4, 2)),\n",
       " Action(pos1=(4, 2), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(2, 3)),\n",
       " Action(pos1=(2, 3), pos2=(2, 4)),\n",
       " Action(pos1=(2, 4), pos2=(3, 4)),\n",
       " Action(pos1=(3, 4), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(2, 3)),\n",
       " Action(pos1=(2, 3), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(0, 2)),\n",
       " Action(pos1=(0, 2), pos2=(0, 1)),\n",
       " Action(pos1=(0, 1), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(1, 1)),\n",
       " Action(pos1=(1, 1), pos2=(0, 1)),\n",
       " Action(pos1=(0, 1), pos2=(0, 2)),\n",
       " Action(pos1=(0, 2), pos2=(1, 2)),\n",
       " Action(pos1=(1, 2), pos2=(1, 3)),\n",
       " Action(pos1=(1, 3), pos2=(1, 4)),\n",
       " Action(pos1=(1, 4), pos2=(2, 4)),\n",
       " Action(pos1=(2, 4), pos2=(3, 4)),\n",
       " Action(pos1=(3, 4), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 0)),\n",
       " Action(pos1=(3, 0), pos2=(2, 0)),\n",
       " Action(pos1=(2, 0), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(2, 0)),\n",
       " Action(pos1=(2, 0), pos2=(3, 0)),\n",
       " Action(pos1=(3, 0), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(4, 2)),\n",
       " Action(pos1=(4, 2), pos2=(4, 1)),\n",
       " Action(pos1=(4, 1), pos2=(3, 1)),\n",
       " Action(pos1=(3, 1), pos2=(2, 1)),\n",
       " Action(pos1=(2, 1), pos2=(2, 2)),\n",
       " Action(pos1=(2, 2), pos2=(2, 3)),\n",
       " Action(pos1=(2, 3), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(3, 4)),\n",
       " Action(pos1=(3, 4), pos2=(4, 4)),\n",
       " Action(pos1=(4, 4), pos2=(4, 3)),\n",
       " Action(pos1=(4, 3), pos2=(4, 2)),\n",
       " Action(pos1=(4, 2), pos2=(3, 2)),\n",
       " Action(pos1=(3, 2), pos2=(3, 3)),\n",
       " Action(pos1=(3, 3), pos2=(4, 3)),\n",
       " Action(pos1=(4, 3), pos2=(4, 4))]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  8,  9,  1, 18],\n",
       "       [22,  0, 15,  5, 17],\n",
       "       [ 2, 11, 21, 16,  4],\n",
       "       [19, 12, 13,  6, 24],\n",
       "       [20,  3,  7, 23, 10]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24,  0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_goal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
